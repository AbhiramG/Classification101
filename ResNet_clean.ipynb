{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "from os import walk\n",
    "from skimage import io\n",
    "from skimage.transform import resize as skresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class class_net(torch.nn.Module):\n",
    "    def __init__(self,n_class = 10, frozen = 0):\n",
    "        super(class_net, self).__init__()\n",
    "        self.net_vgg = models.vgg16(pretrained=True)\n",
    "        \n",
    "        ct = 0\n",
    "        \n",
    "        for i in range(0,frozen):\n",
    "            if (hasattr(self.net_vgg.features[i], 'weight')):\n",
    "                self.net_vgg.features[i].weight.requires_grad = False\n",
    "        \n",
    "        self.net_vgg.classifier = nn.Sequential(\n",
    "                                    nn.Linear(25088,4096),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Dropout(p=0.5,inplace = False),\n",
    "                                    nn.Linear(4096,1024),\n",
    "                                    nn.ReLU(inplace=True),\n",
    "                                    nn.Dropout(p=0.5,inplace = False),\n",
    "                                    nn.Linear(1024,n_class),\n",
    "                                    nn.LogSoftmax(dim=1))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net_vgg(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize(object):\n",
    "\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        \n",
    "        image = skresize(image, self.output_size, anti_aliasing=False)\n",
    "\n",
    "        return image\n",
    "    \n",
    "class RandomCrop(object):\n",
    "\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        \n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w,:]\n",
    "\n",
    "        return image\n",
    "\n",
    "class RandomFlip(object):\n",
    "    def __init__(self, prob):\n",
    "        self.prob = prob\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        coin = np.random.uniform()\n",
    "        if(coin < self.prob):\n",
    "            image = image[::-1,:,:]\n",
    "        \n",
    "        coin = np.random.uniform()\n",
    "        if(coin < self.prob):\n",
    "            image = image[:,::-1,:]\n",
    "\n",
    "        return image\n",
    "\n",
    "    \n",
    "class ToTensor(object):\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        ss = np.shape(image)\n",
    "        image_new =  np.zeros((ss[2],ss[0],ss[1]))\n",
    "        \n",
    "        image_new[0,:,:] = image[:,:,0]\n",
    "        image_new[1,:,:] = image[:,:,1]\n",
    "        image_new[2,:,:] = image[:,:,2]\n",
    "        \n",
    "        image_new = torch.from_numpy(image_new)\n",
    "        \n",
    "        return image_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Clean_dataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "\n",
    "        f = []\n",
    "        for (dirpath, dirnames, filenames) in walk(root_dir):\n",
    "            f.extend(dirnames)\n",
    "            break\n",
    "            \n",
    "        self.transform = transform\n",
    "        \n",
    "        self.class_names = f\n",
    "        self.labels = []\n",
    "        self.images = []\n",
    "        \n",
    "        for i in range(0,len(self.class_names)):\n",
    "            f = []\n",
    "            for (dirpath, dirnames, filenames) in walk(root_dir + self.class_names[i]):\n",
    "                f.extend(filenames)\n",
    "                break\n",
    "            for j in range(0,len(f)):\n",
    "                self.images.append(root_dir + self.class_names[i] + '/' + f[j])\n",
    "                self.labels.append(int(self.class_names[i]))\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        image = io.imread(self.images[idx])\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if(self.transform):\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trans = transforms.Compose([Resize((260,260)),\n",
    "                                RandomCrop((224,224)),\n",
    "                               RandomFlip(0.3),\n",
    "                                ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "train_dataset = Clean_dataset('new_hard/train/', data_trans)\n",
    "traindataloader = DataLoader(train_dataset, batch_size=32,\n",
    "                        shuffle=True, num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    raise Exception(\"You requested GPU support, but there's no GPU on this machine\")\n",
    "\n",
    "    \n",
    "#net = models.vgg16(pretrained=True)\n",
    "#net = net.to(device)\n",
    "#net = nn.Sequential(*list(net.children())[:-1])\n",
    "\n",
    "net = class_net(frozen = 31)\n",
    "net = net.to(device)\n",
    "#summary(net,(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
